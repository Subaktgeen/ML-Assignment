{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q imbalanced-learn"
      ],
      "metadata": {
        "id": "0J9CZJk0m_sW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqKwc9kPmHbu",
        "outputId": "6471e8fe-d8da-4e9c-a2c8-f1f55ac1745d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score (KMeans): 0.13819885307296784\n",
            "Silhouette Score (DBSCAN): -0.13682720246665067\n",
            "Original Class Distribution: {np.int64(0): np.int64(4130), np.int64(1): np.int64(1495)}\n",
            "Balanced Class Distribution: {np.int64(0): np.int64(4130), np.int64(1): np.int64(4130)}\n",
            "\n",
            "ðŸ”¹ Logistic Regression\n",
            "Accuracy: 0.6943852167732765\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.65      0.76      1033\n",
            "           1       0.46      0.81      0.58       374\n",
            "\n",
            "    accuracy                           0.69      1407\n",
            "   macro avg       0.68      0.73      0.67      1407\n",
            "weighted avg       0.79      0.69      0.71      1407\n",
            "\n",
            "Confusion Matrix:\n",
            " [[675 358]\n",
            " [ 72 302]]\n",
            "\n",
            "ðŸ”¹ Decision Tree\n",
            "Accuracy: 0.7199715707178393\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81      1033\n",
            "           1       0.47      0.48      0.48       374\n",
            "\n",
            "    accuracy                           0.72      1407\n",
            "   macro avg       0.64      0.64      0.64      1407\n",
            "weighted avg       0.72      0.72      0.72      1407\n",
            "\n",
            "Confusion Matrix:\n",
            " [[832 201]\n",
            " [193 181]]\n",
            "\n",
            "ðŸ”¹ Random Forest\n",
            "Accuracy: 0.7455579246624022\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      1033\n",
            "           1       0.52      0.47      0.50       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.67      0.66      0.66      1407\n",
            "weighted avg       0.74      0.75      0.74      1407\n",
            "\n",
            "Confusion Matrix:\n",
            " [[872 161]\n",
            " [197 177]]\n",
            "\n",
            "ðŸ”¹ Gradient Boosting\n",
            "Accuracy: 0.7476901208244492\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82      1033\n",
            "           1       0.52      0.64      0.57       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.69      0.71      0.70      1407\n",
            "weighted avg       0.77      0.75      0.76      1407\n",
            "\n",
            "Confusion Matrix:\n",
            " [[812 221]\n",
            " [134 240]]\n",
            "\n",
            "ðŸ”¹ AdaBoost\n",
            "Accuracy: 0.7036247334754797\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.68      0.77      1033\n",
            "           1       0.47      0.78      0.58       374\n",
            "\n",
            "    accuracy                           0.70      1407\n",
            "   macro avg       0.68      0.73      0.68      1407\n",
            "weighted avg       0.78      0.70      0.72      1407\n",
            "\n",
            "Confusion Matrix:\n",
            " [[698 335]\n",
            " [ 82 292]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "\n",
        "# Drop customerID\n",
        "df.drop(\"customerID\", axis=1, inplace=True)\n",
        "\n",
        "# Convert TotalCharges to numeric\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors='coerce')\n",
        "\n",
        "# Drop rows with missing TotalCharges\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda x: LabelEncoder().fit_transform(x))\n",
        "\n",
        "# Clustering\n",
        "features_for_clustering = df.drop(\"Churn\", axis=1)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(features_for_clustering)\n",
        "\n",
        "# KMeans\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
        "sil_kmeans = silhouette_score(X_scaled, kmeans_labels)\n",
        "\n",
        "# DBSCAN\n",
        "dbscan = DBSCAN(eps=1.5, min_samples=5)\n",
        "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
        "sil_dbscan = silhouette_score(X_scaled, dbscan_labels)\n",
        "\n",
        "print(\"Silhouette Score (KMeans):\", sil_kmeans)\n",
        "print(\"Silhouette Score (DBSCAN):\", sil_dbscan)\n",
        "\n",
        "# Classification - target is 'Churn'\n",
        "X = df.drop(\"Churn\", axis=1)\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "# Feature selection\n",
        "selector = SelectKBest(score_func=f_classif, k=5)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# SMOTE\n",
        "print(\"Original Class Distribution:\", dict(zip(*np.unique(y_train, return_counts=True))))\n",
        "min_class_count = min(np.unique(y_train, return_counts=True)[1])\n",
        "k_neighbors = min(5, min_class_count - 1)\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "print(\"Balanced Class Distribution:\", dict(zip(*np.unique(y_train_bal, return_counts=True))))\n",
        "\n",
        "# Classifiers\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier()\n",
        "}\n",
        "\n",
        "# Train and evaluate\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_bal, y_train_bal)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\nðŸ”¹ {name}\")\n",
        "    print(\"Accuracy:\", model.score(X_test, y_test))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('heart.csv')\n",
        "\n",
        "# Show column names to identify target\n",
        "print(\"Columns in dataset:\", df.columns.tolist())\n",
        "\n",
        "# Infer target column\n",
        "# Replace with correct target column name if needed\n",
        "possible_targets = ['target', 'HeartDisease', 'output']\n",
        "target_column = None\n",
        "for col in possible_targets:\n",
        "    if col in df.columns:\n",
        "        target_column = col\n",
        "        break\n",
        "\n",
        "if not target_column:\n",
        "    raise ValueError(\"Target column not found. Please check column names.\")\n",
        "\n",
        "# Encode categorical features if any\n",
        "le = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ----- PCA -----\n",
        "pca = PCA(n_components=3)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf_pca = RandomForestClassifier()\n",
        "clf_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = clf_pca.predict(X_test_pca)\n",
        "\n",
        "print(\"\\n PCA + Random Forest\")\n",
        "print(classification_report(y_test, y_pred_pca))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_pca))\n",
        "\n",
        "# ----- LDA -----\n",
        "lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "X_lda = lda.fit_transform(X_scaled, y)\n",
        "\n",
        "X_train_lda, X_test_lda, y_train, y_test = train_test_split(X_lda, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf_lda = RandomForestClassifier()\n",
        "clf_lda.fit(X_train_lda, y_train)\n",
        "y_pred_lda = clf_lda.predict(X_test_lda)\n",
        "\n",
        "print(\"\\n LDA + Random Forest\")\n",
        "print(classification_report(y_test, y_pred_lda))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lda))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayay8815oWg2",
        "outputId": "86030da0-dbf2-4f3e-a86a-37cd4edf527c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: ['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope', 'HeartDisease']\n",
            "\n",
            " PCA + Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.88      0.82        77\n",
            "           1       0.91      0.81      0.86       107\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n",
            "Confusion Matrix:\n",
            " [[68  9]\n",
            " [20 87]]\n",
            "\n",
            " LDA + Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.87      0.78        77\n",
            "           1       0.89      0.75      0.81       107\n",
            "\n",
            "    accuracy                           0.80       184\n",
            "   macro avg       0.80      0.81      0.80       184\n",
            "weighted avg       0.82      0.80      0.80       184\n",
            "\n",
            "Confusion Matrix:\n",
            " [[67 10]\n",
            " [27 80]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
        "\n",
        "# Drop rows with missing values (if any)\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Show target value distribution\n",
        "print(\"Target Distribution:\\n\", df['y'].value_counts())\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "# Split data before any balancing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Baseline model (before balancing)\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"\\n Before Balancing\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ----------------------------\n",
        "# Apply SMOTE Oversampling\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res_sm, y_res_sm = sm.fit_resample(X, y)\n",
        "\n",
        "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_res_sm, y_res_sm, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train_sm, y_train_sm)\n",
        "y_pred_sm = clf.predict(X_test_sm)\n",
        "\n",
        "print(\"\\n After SMOTE Balancing\")\n",
        "print(classification_report(y_test_sm, y_pred_sm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_sm, y_pred_sm))\n",
        "\n",
        "# ----------------------------\n",
        "# Apply Random Undersampling\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_res_rus, y_res_rus = rus.fit_resample(X, y)\n",
        "\n",
        "X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_res_rus, y_res_rus, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train_rus, y_train_rus)\n",
        "y_pred_rus = clf.predict(X_test_rus)\n",
        "\n",
        "print(\"\\n After RandomUnderSampler\")\n",
        "print(classification_report(y_test_rus, y_pred_rus))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_rus, y_pred_rus))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C83rVyelpHBW",
        "outputId": "fd5ab365-1fbe-449e-c582-887006526d0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Distribution:\n",
            " y\n",
            "0    36548\n",
            "1     4640\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Before Balancing\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95      7303\n",
            "           1       0.65      0.51      0.57       935\n",
            "\n",
            "    accuracy                           0.91      8238\n",
            "   macro avg       0.79      0.74      0.76      8238\n",
            "weighted avg       0.91      0.91      0.91      8238\n",
            "\n",
            "Confusion Matrix:\n",
            " [[7045  258]\n",
            " [ 456  479]]\n",
            "\n",
            " After SMOTE Balancing\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95      7332\n",
            "           1       0.94      0.97      0.95      7288\n",
            "\n",
            "    accuracy                           0.95     14620\n",
            "   macro avg       0.95      0.95      0.95     14620\n",
            "weighted avg       0.95      0.95      0.95     14620\n",
            "\n",
            "Confusion Matrix:\n",
            " [[6891  441]\n",
            " [ 245 7043]]\n",
            "\n",
            " After RandomUnderSampler\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.84      0.88       914\n",
            "           1       0.85      0.94      0.89       942\n",
            "\n",
            "    accuracy                           0.89      1856\n",
            "   macro avg       0.89      0.89      0.89      1856\n",
            "weighted avg       0.89      0.89      0.89      1856\n",
            "\n",
            "Confusion Matrix:\n",
            " [[764 150]\n",
            " [ 58 884]]\n"
          ]
        }
      ]
    }
  ]
}